{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from ai_trainer.models import BlazePoseModel\n",
    "from ai_trainer.drawing import *\n",
    "from ai_trainer.feedback.lunges import give_feedback\n",
    "\n",
    "BLAZEPOSE_MODEL_PATH = \"./models/blazepose_full.onnx\"\n",
    "blazepose_model = BlazePoseModel(model_path=BLAZEPOSE_MODEL_PATH)\n",
    "\n",
    "IMAGE_PATH = \"./assets/8.png\"  # change if needed\n",
    "\n",
    "# read image\n",
    "image = cv2.imread(IMAGE_PATH)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# copy image to plot on it\n",
    "plot_image = image.copy()\n",
    "img_h, img_w = image.shape[:2]\n",
    "# print(img_h, img_w)\n",
    "\n",
    "kps = blazepose_model.predict([image])[0]  # batch size is 1\n",
    "# print(kps[24])\n",
    "# print(kps)\n",
    "probs = kps.T[3]\n",
    "\n",
    "if not all(probs<0):\n",
    "    # denormalize keypoints:\n",
    "    x, y, z = kps.T[:3]\n",
    "    # x_img = x * img_w\n",
    "    # y_img = y * img_h\n",
    "    pose_3d = np.column_stack((x, y, z))\n",
    "    pose_2d = np.column_stack((x, y))\n",
    "    \n",
    "    # plot keypoints on image\n",
    "    sample = draw_pose(\n",
    "        image=plot_image,\n",
    "        keypoints=pose_2d,\n",
    "        disposition=\"mediapipe\", # blazepose keypoints are in mediapipe format\n",
    "        thickness=2,\n",
    "    )\n",
    "\n",
    "    feedback, possible_corrections = give_feedback(pose_3d)\n",
    "    number_corrections = len(list(feedback.keys())[1::])\n",
    "\n",
    "    y_text_pos1 = 0\n",
    "    y_text_pos2 = 0\n",
    "    for correction in possible_corrections:\n",
    "        y_text_pos1+=25\n",
    "        y_text_pos2+=35\n",
    "        if correction in list(feedback.keys()):\n",
    "            sample = draw_text_with_border(\n",
    "                image=sample,\n",
    "                text=feedback[correction],\n",
    "                origin=(10, 70),\n",
    "                font_scale=0.8,\n",
    "                font_face = cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                color_in=(250, 50, 50),\n",
    "                thickness_in=2,\n",
    "                color_out= (0, 0, 0),\n",
    "                thickness_out = 3,\n",
    "     \n",
    "            )\n",
    "            sample = draw_text_with_border(\n",
    "                image=sample,\n",
    "                text=feedback[correction],\n",
    "                origin=(10, 120),\n",
    "                font_scale=0.8,\n",
    "                font_face = cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                color_in=(250, 50, 50),\n",
    "                thickness_in=2,\n",
    "                color_out= (0, 0, 0),\n",
    "                thickness_out = 3,\n",
    "     \n",
    "            )\n",
    "            hip_coord = kps[23]\n",
    "            # draw_dotted_line(sample, hip_coord, start=hip_coord[1]-80, end=hip_coord[1]+20, line_color=(0, 127, 255))\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(plot_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('models/yolo/best.pt')  # pretrained YOLOv8n model\n",
    "\n",
    "# Run batched inference on a list of images\n",
    "results = model(['assets/8.png', 'assets/8.png'], stream=True)  # return a generator of Results objects\n",
    "\n",
    "# Process results generator\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    # result.show()  # display to screen\n",
    "    print(\"1 +\", keypoints)\n",
    "    # result.save(filename='result.jpg')  # save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading https://ultralytics.com/images/bus.jpg to 'bus.jpg'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476k/476k [00:00<00:00, 2.98MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 d:\\AI-Trainer\\bus.jpg: 640x480 4 persons, 105.0ms\n",
      "Speed: 4.0ms preprocess, 105.0ms inference, 1954.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "[[     143.21      444.38     0.97378]\n",
      " [     148.01      435.99     0.85104]\n",
      " [     132.75      435.57     0.96315]\n",
      " [          0           0     0.34978]\n",
      " [     107.11      439.04      0.8844]\n",
      " [     167.94      495.22     0.98505]\n",
      " [      89.54      494.16     0.99312]\n",
      " [     197.81       562.2     0.91766]\n",
      " [     116.57      570.36     0.97998]\n",
      " [     163.37      542.67     0.88269]\n",
      " [     153.51      571.03     0.96137]\n",
      " [     156.04      642.01     0.99648]\n",
      " [     96.572      641.98     0.99789]\n",
      " [     180.67      749.87     0.99313]\n",
      " [     90.863       752.9     0.99599]\n",
      " [     185.52      852.63     0.97393]\n",
      " [     70.856      860.63     0.98095]]\n",
      "[[     0.1768     0.41146]\n",
      " [    0.18273      0.4037]\n",
      " [    0.16389      0.4033]\n",
      " [          0           0]\n",
      " [    0.13224     0.40652]\n",
      " [    0.20734     0.45854]\n",
      " [    0.11054     0.45756]\n",
      " [    0.24421     0.52056]\n",
      " [    0.14392     0.52811]\n",
      " [     0.2017     0.50247]\n",
      " [    0.18952     0.52874]\n",
      " [    0.19264     0.59446]\n",
      " [    0.11923     0.59443]\n",
      " [    0.22304     0.69432]\n",
      " [    0.11218     0.69713]\n",
      " [    0.22904     0.78948]\n",
      " [   0.087476     0.79688]]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('models/yolo/best.pt')  # pretrained YOLOv8n model\n",
    "\n",
    "# Predict with the model\n",
    "results = model('https://ultralytics.com/images/bus.jpg') \n",
    "\n",
    "# Extract keypoint\n",
    "result_keypoint1 = results[0].keypoints.data.cpu().numpy()[0]\n",
    "result_keypoint = results[0].keypoints.xyn.cpu().numpy()[0]\n",
    "# keypoint_data = results[0].cpu().detach().numpy()\n",
    "print(result_keypoint1)\n",
    "print(result_keypoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
