{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from ai_trainer.models import BlazePoseModel\n",
    "from ai_trainer.drawing import *\n",
    "from ai_trainer.feedback.lunges import give_feedback\n",
    "\n",
    "BLAZEPOSE_MODEL_PATH = \"./models/blazepose_full.onnx\"\n",
    "blazepose_model = BlazePoseModel(model_path=BLAZEPOSE_MODEL_PATH)\n",
    "\n",
    "IMAGE_PATH = \"./assets/8.png\"  # change if needed\n",
    "\n",
    "# read image\n",
    "image = cv2.imread(IMAGE_PATH)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# copy image to plot on it\n",
    "plot_image = image.copy()\n",
    "img_h, img_w = image.shape[:2]\n",
    "# print(img_h, img_w)\n",
    "\n",
    "kps = blazepose_model.predict([image])[0]  # batch size is 1\n",
    "# print(kps[24])\n",
    "# print(kps)\n",
    "probs = kps.T[3]\n",
    "\n",
    "if not all(probs<0):\n",
    "    # denormalize keypoints:\n",
    "    x, y, z = kps.T[:3]\n",
    "    # x_img = x * img_w\n",
    "    # y_img = y * img_h\n",
    "    pose_3d = np.column_stack((x, y, z))\n",
    "    pose_2d = np.column_stack((x, y))\n",
    "    \n",
    "    # plot keypoints on image\n",
    "    sample = draw_pose(\n",
    "        image=plot_image,\n",
    "        keypoints=pose_2d,\n",
    "        disposition=\"mediapipe\", # blazepose keypoints are in mediapipe format\n",
    "        thickness=2,\n",
    "    )\n",
    "\n",
    "    feedback, possible_corrections = give_feedback(pose_3d)\n",
    "    number_corrections = len(list(feedback.keys())[1::])\n",
    "\n",
    "    y_text_pos1 = 0\n",
    "    y_text_pos2 = 0\n",
    "    for correction in possible_corrections:\n",
    "        y_text_pos1+=25\n",
    "        y_text_pos2+=35\n",
    "        if correction in list(feedback.keys()):\n",
    "            sample = draw_text_with_border(\n",
    "                image=sample,\n",
    "                text=feedback[correction],\n",
    "                origin=(10, 70),\n",
    "                font_scale=0.8,\n",
    "                font_face = cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                color_in=(250, 50, 50),\n",
    "                thickness_in=2,\n",
    "                color_out= (0, 0, 0),\n",
    "                thickness_out = 3,\n",
    "     \n",
    "            )\n",
    "            sample = draw_text_with_border(\n",
    "                image=sample,\n",
    "                text=feedback[correction],\n",
    "                origin=(10, 120),\n",
    "                font_scale=0.8,\n",
    "                font_face = cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                color_in=(250, 50, 50),\n",
    "                thickness_in=2,\n",
    "                color_out= (0, 0, 0),\n",
    "                thickness_out = 3,\n",
    "     \n",
    "            )\n",
    "            hip_coord = kps[23]\n",
    "            # draw_dotted_line(sample, hip_coord, start=hip_coord[1]-80, end=hip_coord[1]+20, line_color=(0, 127, 255))\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(plot_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('models/yolo/best.pt')  # pretrained YOLOv8n model\n",
    "\n",
    "# Run batched inference on a list of images\n",
    "results = model(['assets/8.png', 'assets/8.png'], stream=True)  # return a generator of Results objects\n",
    "\n",
    "# Process results generator\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    # result.show()  # display to screen\n",
    "    print(\"1 +\", keypoints)\n",
    "    # result.save(filename='result.jpg')  # save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('models/yolo/best.pt')  # pretrained YOLOv8n model\n",
    "\n",
    "# Predict with the model\n",
    "results = model('https://ultralytics.com/images/bus.jpg') \n",
    "\n",
    "# Extract keypoint\n",
    "result_keypoint = results[0].keypoints.xyn.cpu().numpy()[0]\n",
    "print(result_keypoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
